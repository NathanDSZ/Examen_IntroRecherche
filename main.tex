\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{nicefrac}
\usepackage{algorithm}
\usepackage[algo2e]{algorithm2e} 
\usepackage{multirow}
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage{float}
\usepackage{indentfirst}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\title{Examen Initiation à la recherce}
\author{DE SOUZA Nathan}
\date{January 2023}

\begin{document}

\maketitle

\section{Chebyshev coefficients}


    We demonstrate why Chebyshev coefficients, as used
in [37], are not well suited to the regression of continuous
periodic functions through a neural network.

Chebyshev polynomials are obtained through the following
recurrence relation:

\begin{equation}
    \begin{array}{c}
          T_0 \left(x\right) = 1 \\ 
          T_1 \left(x\right) = x \\
          T_{n+1} \left(x\right) = 2 x T_n \left(x\right) - T_{n-1} \left(x\right)
    \end{array}
\end{equation}

Let $N$ be the number of degrees used for interpolation of $\rho$ using the truncated Chebyshev series. Then for $x$ $\in$ $\left[ -1, 1 \right] $ we have:

\begin{equation}
    \rho \left(x\right) = \sum_{n=0}^{N} \alpha_n T_n \left(x\right)
\end{equation}

Since the contour $\rho$ is a continuous periodic function on
$\left[ -1, 1 \right] $, in order to perfectly interpolate it, the Chebyshev
coefficients $\alpha_i$ must satisfy:

\begin{equation}
    \sum_{n=0}^{N} \alpha_n T_n \left(-1\right) = \sum_{n=0}^{N} \alpha_n T_n \left(1\right)
\end{equation}

We also know that Chebyshev polynomials satisfy the
following properties, for all $n \in N $:

\begin{equation}
    \begin{array}{c}
          T_n \left(1\right) = 1 \\ 
          T_{2n} \left(-1\right) = 1 \\
          T_{2n+1} \left(-1\right) = -1
    \end{array}
\end{equation}

Then, we have the following:

\begin{equation}
    \sum_{n=0}^{N/2} \alpha_{2k} - \sum_{n=0}^{N/2} \alpha_{2k+1} = \sum_{n=0}^{N} \alpha_{n} 
\end{equation}

Thus, we have shown that in order to perfectly interpolate
a continuous periodic function, the Chebyshev coefficients
must satisfy the following relationship:

\begin{equation}
    \sum_{n=0}^{N/2} \alpha_{2k+1} = 0
\end{equation}

\Cref{fig:fig7} shows the discontinuities created when this relationship
is not strictly enforced, e.g. when the Chebyshev
coefficients are regressed by a neural network. They appear
at $\theta = 2 \pi$ on every regressed shape.

\section{Implementation details}

We use the MMDetection 2.7.0 object detection toolbox
[4], based onMMCV1.2.1 for easy and fair comparison
with other methods. The underlying framework is PyTorch
1.7.0 with CUDA 10.1. We make use of the updated FFT
package from PyTorch 1.7.0 which allows the use of complex
numbers. We use the Chamfer Distance implementation
from PyTorch3D 0.3.0 [24]. The interpolation scheme
described in section 3 of the main text is implemented as a
module in the MMDetection data loading pipeline using the
\texttt{interp} module from Numpy.

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
         Name-Backbone & DCNv2 & CARAFE & $N_{in}$  & $N_{feat}$ & Time \\
         \hline
         SCR-D53-320 & No & No & 128 & 128 & 20h \\
         SCR-R50-800 & Yes & Yes & 256 & 256 & 40h \\
         NSCR-X101-800 &  Yes &  Yes &  256 &  256 & 80h \\
    \end{tabular}
    \caption{Characteristics of our main networks. Variations are further
explored in our ablation study. DCN refers to the use of Deformable
Convolution v2 [39] layers in the head. CARAFE refers
to the use of the FPN-CARAFE [32] neck. Training time on 8
Tesla V100 GPUs.}
    \label{tab:tabl}
\end{table}

Our networks are trained for 38 epochs using SGD with
momentum (0.9), with an initial learning rate of 0.0003,
batch-size of 16 (2 images per GPU), gradient clipping at a
maximum $L^2$ norm of 45, and employ of a 500 step warmup
with a ratio of 0.001 applied to the learning rate. We
use the multiscale training feature found in MMDetection
to train with image heights of 640 and 800 pixels. We
balanced our loss function terms through trial-and-error,
and settled on the following values: $\lambda_{cls}$=1.0, $\lambda_{cent}$=1.0,
$\lambda_{CD}$=1.0, $\lambda_{perim}$=0.01, $\lambda_{coeff}$=500.0.

Due to software incompatibilities during the conversion
of our DarkNet-53 model for low-power hardware targets,
we had to simplify the architecture by removing deformable
convolutions and CARAFE, as shown in \Cref{tab:tabl}.


\section{Hardware configuration}
This section contains details regarding the embedded
hardware configuration used for the throughput benchmarks
presented in section 4 of the main text.

Our Nvidia Jetson Nano 2GB, Nano 4GB and Xavier
NX development kits are running JetPack 4.5, ONNXRuntime
1.4.0 and TensorRT 7.1.3. The Nano SoC features a
quad-core ARM A53 CPU and a 128 CUDA core Maxwell
GPU. In order to obtain consistent results, we lock the
power consumption at 10W for benchmarking using the
\texttt{jetson\_clocks} tool and cool the heatsink with a Noctua
A4x20 5V PWM fan using the default fan curve. We also
ran our benchmarks on a Jetson Nano 4GB model and found
no performance difference with the 2 GB model. Thus, Table
6 of the main text refers to both of them as ”Nano”.

The Jetson Xavier NX features a 6-core ARM processor,
a 384 CUDA core Volta GPU and 8GB RAM, with a power
consumption of 30W and is running the same setup.

The Intel Movidius Myriad X Vision Processing Unit is
an ultra low-power AI accelerator with a power consumption
of only 1W. It has been used in ESA’s $\phi$-sat-1 Cube-Sat, as well as in smart security cameras, UAVs and industrial
machine vision equipment. We benchmark SCR on the
Myriad X using OpenVino and FP16 precision.

Nvidia GeForce GTX 1080Ti (11GB VRAM, 250W)
benchmarks were run using either the same MMDetection
setup used for training, or TensorRT 7.1.3.

Intel Xeon Silver 4114 CPU benchmarks were run using
the Intel OpenVino toolkit.

\section{Carbon Impact Statement}

While the focus of our work is to create efficient neural
networks that are able to run on very low power devices, we
cannot help but notice that these networks are still created
and trained using power-hungry multi-GPU machines and
wonder about the environmental impact. For this paper, we
missed the opportunity to track the real power consumption
of our experiments, and to estimate its global environmental
footprint, but we are trying as much as we can to publish
these estimations, as recommended in [1, 10, 14].

In order to run the experiments required for our main results
and ablation study, we have used 5864.55 GPU hours
on Nvidia Tesla V100 GPUs, which are rated for a power
consumption of 300W. This, not counting CPUs, cooling,
PSU efficiency, storage of datasets and results, as well as
different trials or hyper-parameter searches on workstations,
amounts to 1759kWh. Since the carbon intensity of our
electricity grid is 10 gCO2/kWh, we estimate an emission
of 17590 gCO2, which is equivalent to 146 km traveled by
car according to [1].

\section{Qualitative results}

In this section, we provide an extended selection of qualitative
results that could not be part of the main paper for
space reasons. Figures 9 and 8 show results from our smallest
and fastest DarkNet-53-based model.


\end{document}
